{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "if '__file__' in locals():\n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "else:\n",
    "    dir_path = os.getcwd()\n",
    "python_path = dir_path + '/../python/'\n",
    "sys.path.append(python_path)\n",
    "\n",
    "\n",
    "import dataset_loader\n",
    "importlib.reload(dataset_loader)\n",
    "from dataset_loader import EM_DATA\n",
    "from dataset_loader import BATCH_SIZE, NBOX_IN,NBOX_OUT,N_CHANNELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = \"/Users/markroza/Documents/work_from_home/NNcourse_project/data/first_tests/single_pdbs/\"\n",
    "outfld = fld+\"../single_pdbs_out/\"\n",
    "if os.path.isdir(outfld) is False:\n",
    "    os.mkdir(outfld)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "em1 = EM_DATA(fld,train_pdbs=['hhhh','nnnn'],test_pdbs=['oooo','cccc','ssss'])\n",
    "if not tf.executing_eagerly():\n",
    "    train_data = em1.train_dataset.make_initializable_iterator()\n",
    "    test_data = em1.test_dataset.make_initializable_iterator()\n",
    "    trn = train_data.get_next()\n",
    "    tst = test_data.get_next()\n",
    "else:\n",
    "    x = np.random.random([BATCH_SIZE]+em1.feature_shape)\n",
    "    y = np.random.random([BATCH_SIZE]+em1.label_shape)\n",
    "    trn = (x,y)\n",
    "    tst= (x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Databaseses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n"
     ]
    }
   ],
   "source": [
    "if not tf.executing_eagerly():\n",
    "    with tf.Session() as sess:\n",
    "            sess.run(train_data.initializer)\n",
    "            sess.run(test_data.initializer)\n",
    "            for k in range(10):\n",
    "                print('TRAIN')\n",
    "                x,y = sess.run(trn)\n",
    "                print(x.shape)\n",
    "                #print(np.sign([np.sum(x[0,:,:,:]),np.sum(x[1,:,:,:]),np.sum(x[2,:,:,:]),np.sum(x[3,:,:,:]),np.sum(x[4,:,:,:]),np.sum(y[:,:,:])]))\n",
    "                print('TEST')\n",
    "                x,y = sess.run(tst)\n",
    "                #print(np.sign([np.sum(x[0,:,:,:]),np.sum(x[1,:,:,:]),np.sum(x[2,:,:,:]),np.sum(x[3,:,:,:]),np.sum(x[4,:,:,:]),np.sum(y[:,:,:])]))\n",
    "else:\n",
    "    print(\"EAGER EXECUTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'net_3d_1' from '/Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import net_3d_1\n",
    "importlib.reload(net_3d_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:43: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:50: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:70: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:72: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:93: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d_transpose instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "nn = net_3d_1.get_net_graph(trn[0],trn[1],0.9,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "(32, 5, 5, 5, 1)\n",
      "URA\n",
      "encoder l1 shape (32, 9, 9, 9, 128)\n",
      "encoder l2 shape (32, 5, 5, 5, 256)\n",
      "encoder l3 shape (32, 3, 3, 3, 512)\n",
      "encoder l4 shape (32, 1, 1, 1, 100)\n",
      "encoder z shape (32, 100)\n",
      "generator l1 shape (32, 2, 2, 2, 512)\n",
      "generator l2 shape (32, 3, 3, 3, 256)\n",
      "generator l3 shape (32, 5, 5, 5, 128)\n",
      "generator c4 shape (32, 5, 5, 5, 1)\n",
      "generator output shape (32, 5, 5, 5, 1)\n",
      "discriminator l1 shape (32, 5, 5, 5, 128)\n",
      "discriminator l2 shape (32, 3, 3, 3, 256)\n",
      "discriminator l3 shape (32, 2, 2, 2, 512)\n",
      "discriminator c4 shape (32, 1, 1, 1, 2)\n",
      "discriminator output shape (32, 1, 1, 1, 2)\n",
      "discriminator logits shape (32, 1, 1, 1, 2)\n",
      "reconstruction_loss shape (32,)\n",
      "KL divergence shape (32,)\n",
      "VAE loss  shape ()\n",
      "VAE_Loss value  244.17633\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        sess.run(train_data.initializer)\n",
    "        sess.run(test_data.initializer)\n",
    "        for k in range(1):\n",
    "            print('TRAIN')\n",
    "            x,y = sess.run(trn)\n",
    "            print(x.shape)\n",
    "            b = sess.run(nn[\"x_3D\"], feed_dict={nn[\"x_3D\"]:y})\n",
    "            print(b.shape)\n",
    "            print(\"URA\")\n",
    "            enc_l1 = sess.run(nn[\"enc\"][\"l1\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l1 shape\",enc_l1.shape)\n",
    "            enc_l2 = sess.run(nn[\"enc\"][\"l2\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l2 shape\",enc_l2.shape)\n",
    "            enc_l3 = sess.run(nn[\"enc\"][\"l3\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l3 shape\",enc_l3.shape)\n",
    "            enc_l4 = sess.run(nn[\"enc\"][\"l4\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l4 shape\",enc_l4.shape)\n",
    "            enc_z = sess.run(nn[\"enc\"][\"z\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder z shape\",enc_z.shape)\n",
    "            gen_l1 = sess.run(nn[\"G_z\"][\"l1\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator l1 shape\",gen_l1.shape)\n",
    "            gen_l2 = sess.run(nn[\"G_z\"][\"l2\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator l2 shape\",gen_l2.shape)\n",
    "            gen_l3 = sess.run(nn[\"G_z\"][\"l3\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator l3 shape\",gen_l3.shape)\n",
    "            gen_c4 = sess.run(nn[\"G_z\"][\"c4\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator c4 shape\",gen_c4.shape)\n",
    "            gen_o = sess.run(nn[\"G_z\"][\"o\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator output shape\",gen_o.shape)\n",
    "            \n",
    "            dsc_l1 = sess.run(nn[\"dsc_real\"][\"l1\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator l1 shape\",dsc_l1.shape)\n",
    "            dsc_l2 = sess.run(nn[\"dsc_real\"][\"l2\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator l2 shape\",dsc_l2.shape)\n",
    "            dsc_l3 = sess.run(nn[\"dsc_real\"][\"l3\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator l3 shape\",dsc_l3.shape)\n",
    "            dsc_c4 = sess.run(nn[\"dsc_real\"][\"c4\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator c4 shape\",dsc_c4.shape)\n",
    "            dsc_o = sess.run(nn[\"dsc_real\"][\"o\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator output shape\",dsc_o.shape)\n",
    "            dsc_logits = sess.run(nn[\"dsc_real\"][\"logits\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator logits shape\",dsc_logits.shape)\n",
    "\n",
    "            rec_loss = sess.run(nn[\"R_L\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"reconstruction_loss shape\",rec_loss.shape)\n",
    "            KL_div = sess.run(nn[\"KL_D\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"KL divergence shape\",KL_div.shape)\n",
    "            VAE_loss = sess.run(nn[\"VAE_L\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"VAE loss  shape\",VAE_loss.shape)\n",
    "            print(\"VAE_Loss value \", VAE_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare New Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'D_loss_2:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "\n",
    "em1 = EM_DATA(fld,train_pdbs=['hhhh','nnnn'],test_pdbs=['oooo','cccc','ssss'])\n",
    "train_data = em1.train_dataset.make_initializable_iterator()\n",
    "test_data = em1.test_dataset.make_initializable_iterator()\n",
    "trn = train_data.get_next()\n",
    "tst = test_data.get_next()\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, NBOX_IN, NBOX_IN, NBOX_IN,N_CHANNELS ])\n",
    "y = tf.placeholder(tf.float32, shape=[BATCH_SIZE, NBOX_OUT, NBOX_OUT, NBOX_OUT,1 ])\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "isTrain = tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "nn = net_3d_1.get_net_graph(x,y,keep_prob,isTrain)\n",
    "tf.summary.scalar('D_loss', nn[\"D_loss\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing the summaries\n",
      "batch: 0\n",
      "D Loss: -0.08530466\n",
      "G Loss: -0.100269005\n",
      "VAE loss: 220.71619\n",
      "KL divergence: 1412.4421\n",
      "reconstruction_loss: 1415.2974\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 1\n",
      "D Loss: 0.04610219\n",
      "G Loss: 0.030548215\n",
      "VAE loss: 161.60153\n",
      "KL divergence: 1034.1062\n",
      "reconstruction_loss: 1437.0669\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 2\n",
      "D Loss: 0.041741192\n",
      "G Loss: -0.013694763\n",
      "VAE loss: 117.43935\n",
      "KL divergence: 751.46497\n",
      "reconstruction_loss: 1468.1486\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 3\n",
      "D Loss: 0.32363406\n",
      "G Loss: 0.31382748\n",
      "VAE loss: 184.11417\n",
      "KL divergence: 1178.1887\n",
      "reconstruction_loss: 1419.8691\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 4\n",
      "D Loss: 0.35923538\n",
      "G Loss: 0.3577973\n",
      "VAE loss: 104.55589\n",
      "KL divergence: 669.0138\n",
      "reconstruction_loss: 1438.4956\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 5\n",
      "D Loss: 0.4895017\n",
      "G Loss: 0.46707398\n",
      "VAE loss: 137.40508\n",
      "KL divergence: 879.25024\n",
      "reconstruction_loss: 1423.0273\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 6\n",
      "D Loss: 0.85456085\n",
      "G Loss: 0.81869644\n",
      "VAE loss: 95.600464\n",
      "KL divergence: 611.702\n",
      "reconstruction_loss: 1409.9656\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 7\n",
      "D Loss: 0.39339373\n",
      "G Loss: 0.44510376\n",
      "VAE loss: 61.688602\n",
      "KL divergence: 394.6584\n",
      "reconstruction_loss: 1486.399\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 8\n",
      "D Loss: 0.0131017715\n",
      "G Loss: -0.017581914\n",
      "VAE loss: 66.18297\n",
      "KL divergence: 423.42224\n",
      "reconstruction_loss: 1487.428\n",
      "###########\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-062ae4b164e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m             _, _, _ = sess.run([nn[\"D_loss\"], nn[\"G_loss\"], nn[\"VAE_L\"], nn[\"mean_KL\"],\\\n\u001b[1;32m     31\u001b[0m             nn[\"mean_recon\"], merged, nn[\"D_optim\"], nn[\"G_optim\"], nn[\"E_optim\"],],\\\n\u001b[0;32m---> 32\u001b[0;31m                         feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: True})\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# open session and initialize all variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    #sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(train_data.initializer)\n",
    "\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    model_path = './network_test_chair/'\n",
    "    if os.path.isdir(model_path) is False:\n",
    "        os.mkdir(model_path)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "        # training-loop\n",
    "    for batch in range(20):\n",
    "        for _ in range(4):\n",
    "            image_in,image_out = sess.run(trn)\n",
    "            sess.run(nn[\"D_optim\"], feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: True})\n",
    "            sess.run(nn[\"clip\"])\n",
    "            loss_d_, loss_g_, _VAE_loss, _KL_divergence, _reconstruction_loss, summary,\\\n",
    "            _, _, _ = sess.run([nn[\"D_loss\"], nn[\"G_loss\"], nn[\"VAE_L\"], nn[\"mean_KL\"],\\\n",
    "            nn[\"mean_recon\"], merged, nn[\"D_optim\"], nn[\"G_optim\"], nn[\"E_optim\"],],\\\n",
    "                        feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: True})\n",
    "            sess.run(nn[\"clip\"])\n",
    "        writer.add_summary(summary,batch)\n",
    "        print('Done writing the summaries')\n",
    "\n",
    "            \n",
    "        if batch % 1 == 0:\n",
    "            print(\"batch:\", batch)\n",
    "            print(\"D Loss:\", loss_d_)\n",
    "            print(\"G Loss:\", loss_g_)\n",
    "            print(\"VAE loss:\", _VAE_loss)\n",
    "            print(\"KL divergence:\", _KL_divergence)\n",
    "            print(\"reconstruction_loss:\", _reconstruction_loss)\n",
    "            print(\"###########\")\n",
    "            if batch % 5 == 0:\n",
    "                G = sess.run(nn[\"G_z\"][\"o\"], feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: False})\n",
    "                np.save(outfld + str(batch) + \".npy\", G)\n",
    "                if batch % 10 == 0:\n",
    "                    saver.save(sess, model_path + str(batch) + \".ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37_tf",
   "language": "python",
   "name": "p37_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

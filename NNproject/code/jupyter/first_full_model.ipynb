{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "if '__file__' in locals():\n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "else:\n",
    "    dir_path = os.getcwd()\n",
    "python_path = dir_path + '/../python/'\n",
    "sys.path.append(python_path)\n",
    "\n",
    "\n",
    "import dataset_loader\n",
    "importlib.reload(dataset_loader)\n",
    "from dataset_loader import EM_DATA\n",
    "from dataset_loader import BATCH_SIZE, NBOX_IN,NBOX_OUT,N_CHANNELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folder and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = \"/Users/markroza/Documents/work_from_home/NNcourse_project/data/first_tests/single_pdbs/\"\n",
    "outfld = fld+\"../single_pdbs_out/\"\n",
    "if os.path.isdir(outfld) is False:\n",
    "    os.mkdir(outfld)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "em1 = EM_DATA(fld,train_pdbs=['hhhh','nnnn'],test_pdbs=['oooo','cccc','ssss'])\n",
    "if not tf.executing_eagerly():\n",
    "    train_data = em1.train_dataset.make_initializable_iterator()\n",
    "    test_data = em1.test_dataset.make_initializable_iterator()\n",
    "    trn = train_data.get_next()\n",
    "    tst = test_data.get_next()\n",
    "else:\n",
    "    x = np.random.random([BATCH_SIZE]+em1.feature_shape)\n",
    "    y = np.random.random([BATCH_SIZE]+em1.label_shape)\n",
    "    trn = (x,y)\n",
    "    tst= (x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Databaseses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n",
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "TEST\n"
     ]
    }
   ],
   "source": [
    "if not tf.executing_eagerly():\n",
    "    with tf.Session() as sess:\n",
    "            sess.run(train_data.initializer)\n",
    "            sess.run(test_data.initializer)\n",
    "            for k in range(10):\n",
    "                print('TRAIN')\n",
    "                x,y = sess.run(trn)\n",
    "                print(x.shape)\n",
    "                #print(np.sign([np.sum(x[0,:,:,:]),np.sum(x[1,:,:,:]),np.sum(x[2,:,:,:]),np.sum(x[3,:,:,:]),np.sum(x[4,:,:,:]),np.sum(y[:,:,:])]))\n",
    "                print('TEST')\n",
    "                x,y = sess.run(tst)\n",
    "                #print(np.sign([np.sum(x[0,:,:,:]),np.sum(x[1,:,:,:]),np.sum(x[2,:,:,:]),np.sum(x[3,:,:,:]),np.sum(x[4,:,:,:]),np.sum(y[:,:,:])]))\n",
    "else:\n",
    "    print(\"EAGER EXECUTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'net_3d_1' from '/Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import net_3d_1\n",
    "importlib.reload(net_3d_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:43: conv3d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:50: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:70: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:72: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/GitHub/work_from_home/NNproject/code/jupyter/../python/net_3d_1.py:93: conv3d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv3d_transpose instead.\n",
      "WARNING:tensorflow:From /Users/markroza/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "nn = net_3d_1.get_net_graph(trn[0],trn[1],0.9,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "(32, 9, 9, 9, 5)\n",
      "(32, 5, 5, 5, 1)\n",
      "URA\n",
      "encoder l1 shape (32, 9, 9, 9, 128)\n",
      "encoder l2 shape (32, 5, 5, 5, 256)\n",
      "encoder l3 shape (32, 3, 3, 3, 512)\n",
      "encoder l4 shape (32, 1, 1, 1, 100)\n",
      "encoder z shape (32, 100)\n",
      "generator l1 shape (32, 2, 2, 2, 512)\n",
      "generator l2 shape (32, 3, 3, 3, 256)\n",
      "generator l3 shape (32, 5, 5, 5, 128)\n",
      "generator c4 shape (32, 5, 5, 5, 1)\n",
      "generator output shape (32, 5, 5, 5, 1)\n",
      "discriminator l1 shape (32, 5, 5, 5, 128)\n",
      "discriminator l2 shape (32, 3, 3, 3, 256)\n",
      "discriminator l3 shape (32, 2, 2, 2, 512)\n",
      "discriminator c4 shape (32, 1, 1, 1, 2)\n",
      "discriminator output shape (32, 1, 1, 1, 2)\n",
      "discriminator logits shape (32, 1, 1, 1, 2)\n",
      "reconstruction_loss shape (32,)\n",
      "KL divergence shape (32,)\n",
      "VAE loss  shape ()\n",
      "VAE_Loss value  244.17633\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        sess.run(train_data.initializer)\n",
    "        sess.run(test_data.initializer)\n",
    "        for k in range(1):\n",
    "            print('TRAIN')\n",
    "            x,y = sess.run(trn)\n",
    "            print(x.shape)\n",
    "            b = sess.run(nn[\"x_3D\"], feed_dict={nn[\"x_3D\"]:y})\n",
    "            print(b.shape)\n",
    "            print(\"URA\")\n",
    "            enc_l1 = sess.run(nn[\"enc\"][\"l1\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l1 shape\",enc_l1.shape)\n",
    "            enc_l2 = sess.run(nn[\"enc\"][\"l2\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l2 shape\",enc_l2.shape)\n",
    "            enc_l3 = sess.run(nn[\"enc\"][\"l3\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l3 shape\",enc_l3.shape)\n",
    "            enc_l4 = sess.run(nn[\"enc\"][\"l4\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder l4 shape\",enc_l4.shape)\n",
    "            enc_z = sess.run(nn[\"enc\"][\"z\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"encoder z shape\",enc_z.shape)\n",
    "            gen_l1 = sess.run(nn[\"G_z\"][\"l1\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator l1 shape\",gen_l1.shape)\n",
    "            gen_l2 = sess.run(nn[\"G_z\"][\"l2\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator l2 shape\",gen_l2.shape)\n",
    "            gen_l3 = sess.run(nn[\"G_z\"][\"l3\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator l3 shape\",gen_l3.shape)\n",
    "            gen_c4 = sess.run(nn[\"G_z\"][\"c4\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator c4 shape\",gen_c4.shape)\n",
    "            gen_o = sess.run(nn[\"G_z\"][\"o\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"generator output shape\",gen_o.shape)\n",
    "            \n",
    "            dsc_l1 = sess.run(nn[\"dsc_real\"][\"l1\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator l1 shape\",dsc_l1.shape)\n",
    "            dsc_l2 = sess.run(nn[\"dsc_real\"][\"l2\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator l2 shape\",dsc_l2.shape)\n",
    "            dsc_l3 = sess.run(nn[\"dsc_real\"][\"l3\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator l3 shape\",dsc_l3.shape)\n",
    "            dsc_c4 = sess.run(nn[\"dsc_real\"][\"c4\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator c4 shape\",dsc_c4.shape)\n",
    "            dsc_o = sess.run(nn[\"dsc_real\"][\"o\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator output shape\",dsc_o.shape)\n",
    "            dsc_logits = sess.run(nn[\"dsc_real\"][\"logits\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"discriminator logits shape\",dsc_logits.shape)\n",
    "\n",
    "            rec_loss = sess.run(nn[\"R_L\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"reconstruction_loss shape\",rec_loss.shape)\n",
    "            KL_div = sess.run(nn[\"KL_D\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"KL divergence shape\",KL_div.shape)\n",
    "            VAE_loss = sess.run(nn[\"VAE_L\"])#, feed_dict={nn[\"x_image\"]:x,nn[\"x_3D\"]:y,nn[\"keep_prob\"]: 0.8, nn[\"isTrain\"]: True})\n",
    "            print(\"VAE loss  shape\",VAE_loss.shape)\n",
    "            print(\"VAE_Loss value \", VAE_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare New Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'D_loss_2:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "\n",
    "em1 = EM_DATA(fld,train_pdbs=['hhhh','nnnn'],test_pdbs=['oooo','cccc','ssss'])\n",
    "train_data = em1.train_dataset.make_initializable_iterator()\n",
    "test_data = em1.test_dataset.make_initializable_iterator()\n",
    "trn = train_data.get_next()\n",
    "tst = test_data.get_next()\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, NBOX_IN, NBOX_IN, NBOX_IN,N_CHANNELS ])\n",
    "y = tf.placeholder(tf.float32, shape=[BATCH_SIZE, NBOX_OUT, NBOX_OUT, NBOX_OUT,1 ])\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "isTrain = tf.placeholder(dtype=tf.bool)\n",
    "\n",
    "nn = net_3d_1.get_net_graph(x,y,keep_prob,isTrain)\n",
    "tf.summary.scalar('D_loss', nn[\"D_loss\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing the summaries\n",
      "batch: 0\n",
      "D Loss: -0.018881321\n",
      "G Loss: -0.01277595\n",
      "VAE loss: 195.52611\n",
      "KL divergence: 1251.2244\n",
      "reconstruction_loss: 1426.6539\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 1\n",
      "D Loss: 0.07095945\n",
      "G Loss: 0.05347306\n",
      "VAE loss: 161.4653\n",
      "KL divergence: 1033.234\n",
      "reconstruction_loss: 1438.6226\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 2\n",
      "D Loss: 0.03639748\n",
      "G Loss: 0.060740277\n",
      "VAE loss: 199.33945\n",
      "KL divergence: 1275.6276\n",
      "reconstruction_loss: 1447.996\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 3\n",
      "D Loss: 0.27678317\n",
      "G Loss: 0.256272\n",
      "VAE loss: 136.39246\n",
      "KL divergence: 872.7696\n",
      "reconstruction_loss: 1422.2363\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 4\n",
      "D Loss: 0.37000018\n",
      "G Loss: 0.34970844\n",
      "VAE loss: 136.77325\n",
      "KL divergence: 875.2068\n",
      "reconstruction_loss: 1421.4287\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 5\n",
      "D Loss: 0.32675457\n",
      "G Loss: 0.34049138\n",
      "VAE loss: 103.44899\n",
      "KL divergence: 661.931\n",
      "reconstruction_loss: 1424.6437\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 6\n",
      "D Loss: 0.25616017\n",
      "G Loss: 0.24627757\n",
      "VAE loss: 79.1597\n",
      "KL divergence: 506.47913\n",
      "reconstruction_loss: 1429.7747\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 7\n",
      "D Loss: 0.16241437\n",
      "G Loss: 0.18737274\n",
      "VAE loss: 81.81728\n",
      "KL divergence: 523.49023\n",
      "reconstruction_loss: 1403.4038\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 8\n",
      "D Loss: 0.49145\n",
      "G Loss: 0.40177312\n",
      "VAE loss: 45.54532\n",
      "KL divergence: 291.34924\n",
      "reconstruction_loss: 1407.8425\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 9\n",
      "D Loss: 0.2518119\n",
      "G Loss: 0.14145884\n",
      "VAE loss: 59.95774\n",
      "KL divergence: 383.58466\n",
      "reconstruction_loss: 1449.0469\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 10\n",
      "D Loss: 0.20905966\n",
      "G Loss: 0.16026542\n",
      "VAE loss: 51.89599\n",
      "KL divergence: 331.99332\n",
      "reconstruction_loss: 1410.3223\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 11\n",
      "D Loss: 1.0243162\n",
      "G Loss: 0.93918097\n",
      "VAE loss: 37.10502\n",
      "KL divergence: 237.32875\n",
      "reconstruction_loss: 1433.814\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 12\n",
      "D Loss: -0.030625775\n",
      "G Loss: -0.09444288\n",
      "VAE loss: 45.70027\n",
      "KL divergence: 292.3371\n",
      "reconstruction_loss: 1446.4729\n",
      "###########\n",
      "Done writing the summaries\n",
      "batch: 13\n",
      "D Loss: 0.9408357\n",
      "G Loss: 0.6905253\n",
      "VAE loss: 53.7143\n",
      "KL divergence: 343.6245\n",
      "reconstruction_loss: 1470.4055\n",
      "###########\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (7, 9, 9, 9, 5) for Tensor 'Placeholder:0', which has shape '(32, 9, 9, 9, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-34f857c3e9b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mimage_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"D_optim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misTrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"clip\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss_d_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_g_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_VAE_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KL_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_reconstruction_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/work_from_home/NNcourse_project/v_env_p37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (7, 9, 9, 9, 5) for Tensor 'Placeholder:0', which has shape '(32, 9, 9, 9, 5)'"
     ]
    }
   ],
   "source": [
    "# open session and initialize all variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    #sess = tf.InteractiveSession()\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(train_data.initializer)\n",
    "\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    model_path = './network_test_chair/'\n",
    "    if os.path.isdir(model_path) is False:\n",
    "        os.mkdir(model_path)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "        # training-loop\n",
    "    for batch in range(20):\n",
    "        for _ in range(4):\n",
    "            image_in,image_out = sess.run(trn)\n",
    "            sess.run(nn[\"D_optim\"], feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: True})\n",
    "            sess.run(nn[\"clip\"])\n",
    "            loss_d_, loss_g_, _VAE_loss, _KL_divergence, _reconstruction_loss, summary,\\\n",
    "            _, _, _ = sess.run([nn[\"D_loss\"], nn[\"G_loss\"], nn[\"VAE_L\"], nn[\"mean_KL\"],\\\n",
    "            nn[\"mean_recon\"], merged, nn[\"D_optim\"], nn[\"G_optim\"], nn[\"E_optim\"],],\\\n",
    "                        feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: True})\n",
    "            sess.run(nn[\"clip\"])\n",
    "        writer.add_summary(summary,batch)\n",
    "        print('Done writing the summaries')\n",
    "\n",
    "            \n",
    "        if batch % 1 == 0:\n",
    "            print(\"batch:\", batch)\n",
    "            print(\"D Loss:\", loss_d_)\n",
    "            print(\"G Loss:\", loss_g_)\n",
    "            print(\"VAE loss:\", _VAE_loss)\n",
    "            print(\"KL divergence:\", _KL_divergence)\n",
    "            print(\"reconstruction_loss:\", _reconstruction_loss)\n",
    "            print(\"###########\")\n",
    "            if batch % 5 == 0:\n",
    "                G = sess.run(nn[\"G_z\"][\"o\"], feed_dict={x: image_in, y: image_out, keep_prob: 0.8, isTrain: False})\n",
    "                np.save(outfld + str(batch) + \".npy\", G)\n",
    "                if batch % 10 == 0:\n",
    "                    saver.save(sess, model_path + str(batch) + \".ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37_tf",
   "language": "python",
   "name": "p37_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
